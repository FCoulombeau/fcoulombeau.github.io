---
layout: post
title: CoVid-19 et interpolation
subtitle: Robustesse du modèle
mathjax: true
comments: true
date: 2020-03-15T04:33:07+02:00
authors: ["FCoulombeau"]
tags: [ Maths,Info,Politique ]
categories: [ Divers ]
image: /img/Cov1503sc.png
slug: covid2
niveau: Société
---

Cet article fait suite à mon [premier article](/2020-03-07-covid1/) où je présentais différentes interpolations possibles du nombre de malades testés positifs au CoViD-19.

# Introduction et mises en garde

L'objectif de cet article est de présenter une analyse **_rudimentaire_** de l'évolution du nombre de cas testés positifs au SARS-CoV-2 en France. Il est important de garder à l'esprit que :

1. Les données fournies par le gouvernement français concernent le **_nombre de cas testés positifs_** : le nombre de malades du CoVid-19 est probablement très supérieur aux données communiquées par le gouvernement.  
  Les dernières estimations sur ce sujet laissent penser qu'il y a entre 10 et 100 fois plus de malades que de cas testés positifs, ce qui à l'heure où j'écris cet article laisse penser qu'il y a entre 50 000 et 500 000 malades en France, voire davantage encore.  
  Les raisons pour lesquelles le nombre de cas testés positifs est si sous-évalué par rapport au nombre de malades sont diverses, mais on peut par exemple citer l'existence de très nombreux cas de malades asymptomatiques, c'est-à-dire ne présentant pas ou peu de symptômes : voir [ici](https://www.liberation.fr/checknews/2020/03/12/y-a-t-il-des-porteurs-asymptomatiques-du-covid-19_1781284) par exemple.
2. Je tente d'interpoler les données du nombre de cas testés positifs à l'aide d'une sigmoïde. À ce titre, il convient de bien comprendre que :
   - mon modèle est purement mathématique et ne reflète en aucun cas la complexité des processus biologiques en jeu;
   - mon modèle a une portée essentiellement pédagogique visant à faire comprendre que l'**_interpolation exponentielle ne peut pas être valide sur le long terme_** : le nombre de cas testés positifs tendra vers une valeur finie dans un pays à population finie;
   - l'objectif de cet article est de tester la robustesse du modèle. On verra que la dernière version en date semble relativement robuste et permet de fournir une prévision relativement fiable du nombre de cas testés positifs à un jour près. **_Cependant_**, parce qu'il s'agit d'une simple interpolation, il ne peut prendre en compte l'évolution de la politique sanitaire et pourrait par exemple sur-évaluer le nombre futur de cas puisque la fermeture des établissements scolaires et universités annoncée le 12 mars, ou encore celle des débits de boisson et autres boîtes de nuit annoncée le 14 mars auront, très probablement, pour conséquence d'enrayer la diffusion du virus.
     De ce point de vue, le modèle pourrait permettre d'observer l'efficacité de ces mesures : plus il sur-évaluera les annonces du nombre de nouveaux cas, plus les mesures se seront montrées efficaces.
3. Je fais amende honorable pour les premières versions de mon algorithme qui sous-évaluaient grandement la vitesse de contagion. L'objectif de cet article est aussi de corriger mes premières erreurs.
4. Pour une analyse bien plus détaillée de l'épidémie et notamment de la nécessité d'un confinement aussi strict que possible, on peut consulter [cet excellent article en anglais](https://medium.com/@tomaspueyo/coronavirus-act-today-or-people-will-die-f4d3d9cd99ca).

# Principe de l'algorithme

Je pars du postulat qu'une approximation grossière du nombre de cas testés positifs peut être obtenue à l'aide d'une sigmoïde :

$$N(t)=\dfrac{c}{1+e^{-a(t-t_0)}}$$

où :
- $c$ représente le nombre asymptotique de cas testés positifs en fin d'épidémie;
- $a$ représente la contagiosité du virus en début d'épidémie - plus précisément $\alpha=e^a-1$ représente la proportion de nouveaux cas par jour en tout début d'épidémie;
- $t_0$ représente le moment où l'**_inflexion_** se produit, c'est-à-dire le moment où le nombre de nouveaux cas par jour commence à diminuer - de façon pérenne - par rapport aux nombres observés dans le passé.

La difficulté est d'obtenir les constantes réelles $a$, $c$ et $t_0$ sur la base des données fournies par les autorités sanitaires tous les soirs depuis plusieurs semaines.

La méthode que j'utilise est la suivante :
- pour beaucoup de valeurs de $c$ comprises entre le nombre de cas testés positifs actuels et le nombre d'habitants en France, on obtient $a$ et $t_0$ à l'aide d'une régression linéaire (je préciserai plus loin comment j'effectue cette régression);
- on retient la valeur de $c$ minimisant la somme des carrés des écarts entre les données fournies et les prévisions faites par le modèle;
- on retient aussi une valeur $c_M$ supérieure à $c$ pour laquelle la somme des carrés entre données et prévisions est inférieure à $1,5$ fois la valeur optimale précédemment calculée. Cette valeur $c_M$, ainsi que les valeurs $a_M$ et $t_M$ correspondantes, seront appelées par la suite **_coefficients de l'hypothèse pessimiste_**.

Concernant la régression linéaire permettant d'obtenir $a$ et $t_0$ :
- de façon équivalente au postulat émis sur le nombre de cas, on a $a(t-t_0)\approx \ln\left(\frac{N(t)}{c-N(t)}\right)$.  
  Partant des données officielles, on calcule donc $L(t)=\ln\left(\frac{N(t)}{c-N(t)}\right)$ pour chaque valeur de $c$ retenue et pour les valeurs de $N$ connues.
- **_Ces valeurs de $L(t)$ sont alors pondérées par la valeur de $N(t)$_** : c'est la principale différence entre l'algorithme que je présentais dans mon précédent article.  
  L'objectif est double :
   1. Faire en sorte que l'optimisation des coefficients $a$ et $t_0$ minimise un écart tenant compte de l'importance croissante du nombre de cas testés positifs;
   2. Attribuer un poids plus important aux dernières données obtenues pour tenir compte des évolutions récentes de l'épidémie.
   
